{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Networks\n",
    "\n",
    "This notebook, adapted from Deeplearning.ai's Deep Learning course, focuses on constructing a deep convolutional network using Residual Networks (ResNets). While very deep networks can represent intricate functions, training them effectively can be challenging. Residual Networks, introduced by [He et al.](https://arxiv.org/pdf/1512.03385.pdf), address these challenges and enable the training of much deeper networks.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "- Implement the foundational building blocks of ResNets using Keras\n",
    "- Combine these building blocks to develop and train a state-of-the-art neural network for image classification\n",
    "- Incorporate a skip connection into the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# uncomment the following line to install the packages.\n",
    "# !pip install numpy h5py matplotlib scipy Pillow pandas tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from resnets_utils import *\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "\n",
    "from test_utils import summary, comparator\n",
    "import public_tests\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Very Deep Neural Networks\n",
    "\n",
    "In the previous week, the focus was on building convolutional neural networks first manually with numpy, and then using TensorFlow and Keras.\n",
    "\n",
    "Recent advancements in neural networks have led to the development of extremely deep networks, evolving from just a few layers (e.g., AlexNet) to over a hundred layers.\n",
    "\n",
    "- **Advantages of Deep Networks:** Very deep networks can represent complex functions and learn features at multiple levels of abstraction. Shallow layers can detect basic features like edges, while deeper layers can capture more intricate patterns.\n",
    "\n",
    "- **Training Difficulties:** Despite their potential, deeper networks pose significant challenges. One major issue is vanishing gradients, where the gradient signal can quickly diminish to zero, making gradient descent slow and ineffective.\n",
    "\n",
    "- **Gradient Propagation:** During backpropagation, gradients are multiplied by the weight matrix at each layer, which can cause them to decrease exponentially or, in rare cases, increase uncontrollably (a phenomenon known as exploding gradients).\n",
    "\n",
    "- **Training Observations:** As training progresses, the magnitude of gradients for the shallower layers may rapidly decrease to zero, as illustrated below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/vanishing_grad_kiank.png\" style=\"width:450px;height:220px;\">\n",
    "<caption><center> <u> <font> <b>Figure 1</b> </u><font>  : <b>Vanishing gradient</b> <br> The speed of learning decreases very rapidly for the shallower layers as the network trains </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Residual Network\n",
    "\n",
    "In Residual Networks (ResNets), a \"shortcut\" or \"skip connection\" enables the model to bypass certain layers:\n",
    "\n",
    "<img src=\"images/skip_connection_kiank.png\" style=\"width:650px;height:200px;\">\n",
    "<caption><center> <u> <font> <b>Figure 2</b> </u><font>  : A ResNet block illustrating a skip connection <br> </center></caption>\n",
    "\n",
    "The left side of the image displays the \"main path\" through the network, while the right side incorporates a shortcut that adds to the main path. By stacking these ResNet blocks, a very deep network can be constructed.\n",
    "\n",
    "ResNet blocks with shortcuts facilitate the learning of identity functions, which allows the addition of more blocks with minimal impact on training performance. This ease of learning an identity function is believed to contribute significantly to the outstanding performance of ResNets, potentially more so than the reduction of vanishing gradients.\n",
    "\n",
    "There are two primary types of blocks in ResNets, depending on whether the input and output dimensions are the same or different: the \"identity block\" and the \"convolutional block.\" Both types will be implemented in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Identity Block\n",
    "\n",
    "The identity block is a fundamental component of ResNets, used when the input activation (e.g., $a^{[l]}$) has the same dimensions as the output activation (e.g., $a^{[l+2]}$). The diagram below illustrates the individual steps involved in the identity block:\n",
    "\n",
    "<img src=\"images/idblock2_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font> <b>Figure 3</b> </u><font>  : <b>Identity block.</b> Skip connection \"skips over\" 2 layers. </center></caption>\n",
    "\n",
    "In this diagram, the upper path represents the \"shortcut path,\" and the lower path represents the \"main path.\" The diagram includes CONV2D and ReLU steps in each layer, with an added BatchNorm step to accelerate training. BatchNorm is simple to implement in Keras, requiring just one line of code.\n",
    "\n",
    "In this exercise, a slightly enhanced version of the identity block will be implemented, where the skip connection \"skips over\" 3 hidden layers instead of 2. This updated block is depicted below:\n",
    "\n",
    "<img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font> <b>Figure 4</b> </u><font>  : <b>Identity block.</b> Skip connection \"skips over\" 3 layers.</center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are the individual steps:\n",
    "\n",
    "First component of main path: \n",
    "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`. \n",
    "- The first BatchNorm is normalizing the 'channels' axis.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "Second component of main path:\n",
    "- The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is \"same\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`.\n",
    "- The second BatchNorm is normalizing the 'channels' axis.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters.\n",
    "\n",
    "Third component of main path:\n",
    "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random uniform initialization: `kernel_initializer = initializer(seed=0)`. \n",
    "- The third BatchNorm is normalizing the 'channels' axis.\n",
    "- Note that there is **no** ReLU activation function in this component. \n",
    "\n",
    "Final step: \n",
    "- The `X_shortcut` and the output from the 3rd layer `X` are added together.\n",
    "- **Hint**: The syntax will look something like `Add()([var1,var2])`\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identity_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0017b68317ffa974",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. we'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ## Second component of main path\n",
    "    ## Set the padding = 'same'\n",
    "    X = Conv2D(filters = F2, kernel_size = f,strides = (1, 1),padding='same',kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ## Third component of main path\n",
    "    ## Set the padding = 'valid'\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    \n",
    "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    ## This shows the flexibility of the Functional API to create a shortcut path.\n",
    "    X = Add()([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e73a8466b807e261",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWith training=False\u001b[0m\n",
      "\n",
      "[[[  0.        0.        0.        0.     ]\n",
      "  [  0.        0.        0.        0.     ]]\n",
      "\n",
      " [[192.99992 192.99992 192.99992  96.99996]\n",
      "  [ 96.99996  96.99996  96.99996  48.99998]]\n",
      "\n",
      " [[578.99976 578.99976 578.99976 290.99988]\n",
      "  [290.99988 290.99988 290.99988 146.99994]]]\n",
      "96.99996\n",
      "\n",
      "\u001b[1mWith training=True\u001b[0m\n",
      "\n",
      "[[[0.      0.      0.      0.     ]\n",
      "  [0.      0.      0.      0.     ]]\n",
      "\n",
      " [[0.40732 0.40732 0.40732 0.40732]\n",
      "  [0.40732 0.40732 0.40732 0.40732]]\n",
      "\n",
      " [[5.00011 5.00011 5.00011 3.25955]\n",
      "  [3.25955 3.25955 3.25955 2.40732]]]\n",
      "\u001b[32mAll tests passed!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_learning_phase(False)\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "\n",
    "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1))\n",
    "print('\\033[1mWith training=False\\033[0m\\n')\n",
    "A3np = A3.numpy()\n",
    "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
    "print(resume[1, 1, 0])\n",
    "\n",
    "tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1))\n",
    "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "\n",
    "public_tests.identity_block_test(identity_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected value**\n",
    "\n",
    "```\n",
    "With training=False\n",
    "\n",
    "[[[  0.        0.        0.        0.     ]\n",
    "  [  0.        0.        0.        0.     ]]\n",
    "\n",
    " [[192.99992 192.99992 192.99992  96.99996]\n",
    "  [ 96.99996  96.99996  96.99996  48.99998]]\n",
    "\n",
    " [[578.99976 578.99976 578.99976 290.99988]\n",
    "  [290.99988 290.99988 290.99988 146.99994]]]\n",
    "96.99996\n",
    "\n",
    "With training=True\n",
    "\n",
    "[[[0.      0.      0.      0.     ]\n",
    "  [0.      0.      0.      0.     ]]\n",
    "\n",
    " [[0.40732 0.40732 0.40732 0.40732]\n",
    "  [0.40732 0.40732 0.40732 0.40732]]\n",
    "\n",
    " [[5.00011 5.00011 5.00011 3.25955]\n",
    "  [3.25955 3.25955 3.25955 2.40732]]]\n",
    "[[[  0.        0.        0.        0.     ]\n",
    "  [  0.        0.        0.        0.     ]]\n",
    "All tests passed!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Convolutional Block\n",
    "\n",
    "The ResNet \"convolutional block\" is used when the input and output dimensions differ. Unlike the identity block, the convolutional block includes a CONV2D layer in the shortcut path to adjust dimensions:\n",
    "\n",
    "<img src=\"images/convblock_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font> <b>Figure 4</b> </u><font>  : <b>Convolutional block</b> </center></caption>\n",
    "\n",
    "Key points about the convolutional block:\n",
    "\n",
    "* The CONV2D layer in the shortcut path resizes the input $x$ to a dimension that matches the final addition step, similar to the matrix $W_s$ discussed in the lecture.\n",
    "* To reduce the height and width of the activation dimensions by a factor of 2, a 1x1 convolution with a stride of 2 can be used.\n",
    "* The CONV2D layer in the shortcut path does not apply any non-linear activation function. Its primary role is to perform a learned linear transformation that adjusts the dimensions for the addition step.\n",
    "* The `initializer` argument, necessary for grading purposes, is set by default to [glorot_uniform](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform).\n",
    "\n",
    "The details of the convolutional block are as follows:\n",
    "\n",
    "First component of main path:\n",
    "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\". Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
    "- The first BatchNorm is normalizing the 'channels' axis.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "Second component of main path:\n",
    "- The second CONV2D has $F_2$ filters of shape (f,f) and a stride of (1,1). Its padding is \"same\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
    "- The second BatchNorm is normalizing the 'channels' axis.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "Third component of main path:\n",
    "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
    "- The third BatchNorm is normalizing the 'channels' axis. Note that there is no ReLU activation function in this component. \n",
    "\n",
    "Shortcut path:\n",
    "- The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\".  Use 0 as the `glorot_uniform` seed `kernel_initializer = initializer(seed=0)`.\n",
    "- The BatchNorm is normalizing the 'channels' axis. \n",
    "\n",
    "Final step: \n",
    "- The shortcut and the main path values are added together.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolutional_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df47af4847e5335f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
    "                   also called Xavier uniform initializer.\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    \n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ## Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = f,strides = (1, 1),padding='same',kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    ## Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    \n",
    "    ##### SHORTCUT PATH ##### \n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-95c291eb244218fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.         0.         0.6444886  0.         0.13933674 0.78552186]\n",
      "  [0.01692437 0.         0.70562446 0.         0.28001052 0.6748623 ]]\n",
      "\n",
      " [[0.         0.         0.6704905  0.         0.18277568 0.7510617 ]\n",
      "  [0.         0.         0.6880039  0.         0.25766334 0.6797846 ]]], shape=(2, 2, 6), dtype=float32)\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "public_tests.convolutional_block_test(convolutional_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected value**\n",
    "\n",
    "```\n",
    "[[[0.         0.         0.6444886  0.         0.13933674 0.78552186]\n",
    "  [0.01692437 0.         0.70562446 0.         0.28001052 0.6748623 ]]\n",
    "\n",
    " [[0.         0.         0.6704905  0.         0.18277568 0.7510617 ]\n",
    "  [0.         0.         0.6880039  0.         0.25766334 0.6797846 ]]], shape=(2, 2, 6), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a ResNet Model (50 layers)\n",
    "\n",
    "With the necessary blocks in place, it's time to construct a deep ResNet model. The figure below details the architecture of this neural network. In the diagram, `ID BLOCK` refers to an `Identity block`, and `ID BLOCK` x3 indicates stacking 3 identity blocks together.\n",
    "\n",
    "<img src=\"images/resnet_kiank.png\" style=\"width:850px;height:150px;\">\n",
    "<caption><center> <u> <font> <b>Figure 5</b> </u><font>  : <b>ResNet-50 model</b> </center></caption>\n",
    "\n",
    "The ResNet-50 model includes the following components:\n",
    "- Zero-padding: Pads the input with a (3,3) padding.\n",
    "- Stage 1:\n",
    "    - 2D Convolution: 64 filters of shape (7,7) with a stride of (2,2).\n",
    "    - BatchNorm: Applied to the 'channels' axis of the input.\n",
    "    - MaxPooling: Uses a (3,3) window with a stride of (2,2).\n",
    "- Stage 2:\n",
    "    - Convolutional Block: Three sets of filters [64,64,256], with a filter size \"f\" of 3 and a stride \"s\" of 1.\n",
    "    - Identity Blocks: Two blocks with filters [64,64,256] and a filter size \"f\" of 3.\n",
    "- Stage 3:\n",
    "    - Convolutional Block: Three sets of filters [128,128,512], with a filter size \"f\" of 3 and a stride \"s\" of 2.\n",
    "    - Identity Blocks: Three blocks with filters [128,128,512] and a filter size \"f\" of 3.\n",
    "- Stage 4:\n",
    "    - Convolutional Block: Three sets of filters [256,256,1024], with a filter size \"f\" of 3 and a stride \"s\" of 2.\n",
    "    - Identity Blocks: Five blocks with filters [256,256,1024] and a filter size \"f\" of 3.\n",
    "- Stage 5:\n",
    "    - Convolutional Block: Three sets of filters [512,512,2048], with a filter size \"f\" of 3 and a stride \"s\" of 2.\n",
    "    - Identity Blocks: Two blocks with filters [512,512,2048] and a filter size \"f\" of 3.\n",
    "- 2D Average Pooling: Uses a (2,2) window.\n",
    "- Flatten: No hyperparameters.\n",
    "- Fully Connected (Dense) Layer: Reduces the input to the number of classes with a softmax activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10dc95a4cf6275b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6, training=False):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "    # Use the instructions above in order to implement all of the Stages below\n",
    "    # Make sure you don't miss adding any required parameter\n",
    "    \n",
    "    ## Stage 3\n",
    "    # `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)\n",
    "    \n",
    "    # the 3 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3,  [128,128,512])\n",
    "    X = identity_block(X, 3,  [128,128,512])\n",
    "    X = identity_block(X, 3,  [128,128,512])\n",
    "\n",
    "    # Stage 4\n",
    "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    \n",
    "    # the 5 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    for  i in range(5):\n",
    "        X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5\n",
    "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    \n",
    "    # the 2 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL\n",
    "    X = AveragePooling2D((2, 2))(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 32, 32, 64)   9472        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 32, 32, 64)  256         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 15, 15, 64)   0           ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 15, 15, 64)   4160        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 15, 15, 64)  256         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 15, 15, 64)  256         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 15, 15, 256)  16640       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_25[0][0]', \n",
      "                                                                  'batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 15, 15, 256)  0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 15, 15, 64)  256         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 15, 15, 64)  256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 15, 15, 256)  0           ['activation_22[0][0]',          \n",
      "                                                                  'batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 15, 15, 256)  0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 15, 15, 64)  256         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 15, 15, 64)  256         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_32 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 15, 15, 256)  0           ['activation_25[0][0]',          \n",
      "                                                                  'batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 15, 15, 256)  0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 8, 8, 128)   512         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 8, 8, 128)   512         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_35[0][0]', \n",
      "                                                                  'batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 8, 8, 512)    0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 8, 8, 128)   512         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 8, 8, 128)   512         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 8, 8, 512)    0           ['activation_31[0][0]',          \n",
      "                                                                  'batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 8, 8, 512)    0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 8, 8, 128)   512         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 8, 8, 128)   512         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 8, 8, 512)    0           ['activation_34[0][0]',          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 8, 8, 512)    0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 8, 8, 128)   512         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 8, 8, 128)   512         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 8, 8, 512)    0           ['activation_37[0][0]',          \n",
      "                                                                  'batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 8, 8, 512)    0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 4, 4, 1024)   525312      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_48[0][0]', \n",
      "                                                                  'batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 4, 4, 1024)   0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 4, 4, 1024)   0           ['activation_43[0][0]',          \n",
      "                                                                  'batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 4, 4, 1024)   0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_46[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_53 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 4, 4, 1024)   0           ['activation_46[0][0]',          \n",
      "                                                                  'batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 4, 4, 1024)   0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 4, 4, 1024)   0           ['activation_49[0][0]',          \n",
      "                                                                  'batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 4, 4, 1024)   0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 4, 4, 1024)   0           ['activation_52[0][0]',          \n",
      "                                                                  'batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 4, 4, 1024)   0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_63[0][0]'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 4, 4, 1024)   0           ['activation_55[0][0]',          \n",
      "                                                                  'batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 4, 4, 1024)   0           ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 2, 2, 512)    524800      ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 2, 2, 2048)   2099200     ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_67[0][0]', \n",
      "                                                                  'batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 2, 2, 2048)   0           ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 2, 2, 2048)   0           ['activation_61[0][0]',          \n",
      "                                                                  'batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 2, 2, 2048)   0           ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_21 (Add)                   (None, 2, 2, 2048)   0           ['activation_64[0][0]',          \n",
      "                                                                  'batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 2, 2, 2048)   0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['activation_67[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            12294       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-866b891ec47ccb7b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAll tests passed!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from outputs import ResNet50_summary\n",
    "\n",
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "\n",
    "comparator(summary(model), ResNet50_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the Keras Tutorial Notebook, prior to training a model, you need to configure the learning process by compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00015)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now ready to be trained. The only thing you need now is a dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load your old friend, the SIGNS dataset.\n",
    "\n",
    "<img src=\"images/signs_data_kiank.png\" style=\"width:450px;height:250px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 6</b> </u><font color='purple'>  : <b>SIGNS dataset</b> </center></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model on 10 epochs with a batch size of 32. On a GPU, it should take less than 2 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - 16s 63ms/step - loss: 1.7726 - accuracy: 0.3093\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 2s 50ms/step - loss: 1.2026 - accuracy: 0.5389\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 2s 51ms/step - loss: 0.8123 - accuracy: 0.6861\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 2s 51ms/step - loss: 0.5453 - accuracy: 0.8019\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 2s 50ms/step - loss: 0.4033 - accuracy: 0.8454\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 2s 51ms/step - loss: 0.3355 - accuracy: 0.8778\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 2s 51ms/step - loss: 0.3137 - accuracy: 0.8935\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 2s 50ms/step - loss: 0.2120 - accuracy: 0.9278\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 2s 50ms/step - loss: 0.1411 - accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 2s 49ms/step - loss: 0.0844 - accuracy: 0.9722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22ca015550>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "```\n",
    "Epoch 1/10\n",
    "34/34 [==============================] - 16s 64ms/step - loss: 1.7770 - accuracy: 0.3111\n",
    "Epoch 2/10\n",
    "34/34 [==============================] - 2s 50ms/step - loss: 1.1800 - accuracy: 0.5583\n",
    "Epoch 3/10\n",
    "34/34 [==============================] - 2s 51ms/step - loss: 0.7900 - accuracy: 0.6935\n",
    "Epoch 4/10\n",
    "34/34 [==============================] - 2s 50ms/step - loss: 0.5295 - accuracy: 0.8065\n",
    "Epoch 5/10\n",
    "34/34 [==============================] - 2s 50ms/step - loss: 0.3665 - accuracy: 0.8648\n",
    "Epoch 6/10\n",
    "34/34 [==============================] - 2s 50ms/step - loss: 0.3032 - accuracy: 0.8880\n",
    "Epoch 7/10\n",
    "34/34 [==============================] - 2s 51ms/step - loss: 0.2456 - accuracy: 0.9194\n",
    "Epoch 8/10\n",
    "34/34 [==============================] - 2s 51ms/step - loss: 0.2123 - accuracy: 0.9278\n",
    "Epoch 9/10\n",
    "34/34 [==============================] - 2s 50ms/step - loss: 0.2113 - accuracy: 0.9389\n",
    "Epoch 10/10\n",
    "34/34 [==============================] - 2s 50ms/step - loss: 0.1469 - accuracy: 0.9491\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this model (trained on only two epochs) performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 11ms/step - loss: 0.5321 - accuracy: 0.8583\n",
      "Loss = 0.5321382880210876\n",
      "Test Accuracy = 0.8583333492279053\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>Test Accuracy</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           >0.70\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It tends to get much better performance when trained for ~20 epochs, but this does take more than an hour when training on a CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It may take ≈1min to load the model\n",
    "pre_trained_model = load_model('resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 9ms/step - loss: 0.1596 - accuracy: 0.9500\n",
      "Loss = 0.15958724915981293\n",
      "Test Accuracy = 0.949999988079071\n"
     ]
    }
   ],
   "source": [
    "preds = pre_trained_model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap**:\n",
    "\n",
    "- Very deep \"plain\" networks don't work in practice because vanishing gradients make them hard to train.  \n",
    "- Skip connections help address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function. \n",
    "- There are two main types of blocks: The **identity block** and the **convolutional block**. \n",
    "- Very deep Residual Networks are built by stacking these blocks together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test image outside SIGNS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (1, 64, 64, 3)\n",
      "1/1 [==============================] - 1s 836ms/step\n",
      "Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] =  [[9.3391151e-05 4.2750672e-02 9.2499280e-01 4.2030567e-04 3.1706784e-02\n",
      "  3.5941892e-05]]\n",
      "Class: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255.0\n",
    "x2 = x \n",
    "print('Input image shape:', x.shape)\n",
    "imshow(img)\n",
    "prediction = pre_trained_model.predict(x2)\n",
    "print(\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \", prediction)\n",
    "print(\"Class:\", np.argmax(prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with high accuracy, the model might perform poorly on a new set of images. Factors such as the shape of the pictures, lighting conditions, and preprocessing steps can impact the model's performance. Reflecting on everything learned in this specialization, consider what might be causing these discrepancies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 64)   9472        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNormalization)  (None, 32, 32, 64)   256         ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 64)   0           ['bn_conv1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 15, 15, 64)   0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 15, 15, 64)   4160        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 15, 15, 64)   36928       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 15, 15, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 15, 15, 256)  16640       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 15, 15, 256)  1024       ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 15, 15, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 15, 15, 64)  256         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 15, 15, 64)  256         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 15, 15, 256)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 15, 15, 64)  256         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 15, 15, 64)  256         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_14[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 15, 15, 256)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 128)   512         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 8, 128)   512         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_19[0][0]', \n",
      "                                                                  'batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 8, 8, 512)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 8, 8, 128)   512         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 8, 8, 128)   512         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_23[0][0]', \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 8, 8, 512)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 8, 8, 128)   512         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 8, 8, 128)   512         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_26[0][0]', \n",
      "                                                                  'activation_21[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 8, 8, 512)    0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 8, 8, 128)   512         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 8, 8, 128)   512         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_29[0][0]', \n",
      "                                                                  'activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 8, 8, 512)    0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 4, 4, 1024)   525312      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 4, 4, 1024)   0           ['batch_normalization_32[0][0]', \n",
      "                                                                  'batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 4, 4, 1024)   0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_36[0][0]', \n",
      "                                                                  'activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 4, 4, 1024)   0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_38[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_39[0][0]', \n",
      "                                                                  'activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 4, 4, 1024)   0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_42[0][0]', \n",
      "                                                                  'activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 4, 4, 1024)   0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_45[0][0]', \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 4, 4, 1024)   0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_49 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_48[0][0]', \n",
      "                                                                  'activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 4, 4, 1024)   0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 2, 2, 512)    524800      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 2, 2, 2048)   2099200     ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_51[0][0]', \n",
      "                                                                  'batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 2, 2, 2048)   0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_55[0][0]', \n",
      "                                                                  'activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 2, 2, 2048)   0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_58[0][0]', \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 2, 2, 2048)   0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['activation_54[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " fc6 (Dense)                    (None, 6)            12294       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
